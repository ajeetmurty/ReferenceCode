
________________________________________________________________

cloudera ops - 

info - http://www.cloudera.com/content/cloudera-content/cloudera-docs/HadoopTutorial/CDH4/Hadoop-Tutorial/ht_usage.html?scroll=topic_5_2

create hdfs dir - 
	$ sudo bash
	$ su hdfs
	$ hadoop fs -mkdir /user/cloudera 
	$ hadoop fs -chown cloudera /user/cloudera
	$ exit
	$ su cloudera
	$ hadoop fs -mkdir /user/cloudera/test /user/cloudera/test/input

upload to hdfs dir - 
	hadoop fs -put source.file /user/cloudera/test/input 

run mapreduce job - 
	right click on eclipse mapreduce project and click run_as->maven_install
	copy generated jar to vm - /home/cloudera/test/mapreduce-0.0.1.jar
	run command - 
		hadoop jar <jar name> <package name and main class> <dir that contains input file/s> <dir that will contain output>
		hadoop jar mapreduce-0.0.1.jar ajeetmurty.reference.mapreduce.LogCount /user/cloudera/test/input /user/cloudera/test/output
	delete output dir - 
		hadoop fs -rm -r /user/cloudera/test/output

browsing hdfs - 
	hadoop fs -cat /user/cloudera/test/output/part-00000 >> output.txt
	hadoop fs -ls -h /user/cloudera/test/output
	hadoop fs -rm -r /user/cloudera/test/output

browse hdfs via browser - 
	cloudera home - http://localhost.localdomain:7180/cmf/home
	cdh browser - hdfs1 >> instances >> namenode (localhost) >> NameNode Web UI >> Browse the filesystem.
	hue browser - hue1 >> Hue Web UI >> Go! >> Hue Home >> Files.


________________________________________________________________



